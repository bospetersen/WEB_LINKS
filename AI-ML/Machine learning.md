 
# Machine Learning
## Documentation
* [keras.io](https://keras.io/api/)
* [tensorflow.org](https://www.tensorflow.org/api_docs)
  * [tensorflow.org - lite](https://www.tensorflow.org/lite/api_docs)
* [pytorch.org](https://pytorch.org/)
  * [pytorch.org/docs](https://pytorch.org/docs/stable/index.html)
  * [pytorch.org/ecosystem](https://pytorch.org/ecosystem/)
  * [pytorch.org/mobile](https://pytorch.org/mobile/home/)
  * [pytorch.org/resources](https://pytorch.org/resources/)
* [pandas.pydata.org/docs](https://pandas.pydata.org/docs/)
  * [numfocus.org](https://numfocus.org/)
* [numpy.org/doc/stable](https://numpy.org/doc/stable/)
  * [numpy.org/doc/stable/reference/index.html](https://numpy.org/doc/stable/reference/index.html)
* [scikit-learn.org](https://scikit-learn.org/stable/)
  * [scikit-learn.org/stable/modules/classes](https://scikit-learn.org/stable/modules/classes.html)
* [scipy.org](https://scipy.org/)
  * [docs.scipy.org](https://docs.scipy.org/doc/scipy/)
* [xgboost.ai](https://xgboost.ai/)
  * [XGBoost - Documentation](https://xgboost.readthedocs.io/en/stable/)
  * [XGBoost Python Package](https://xgboost.readthedocs.io/en/stable/python/index.html)
* [statsmodels.org](https://www.statsmodels.org/stable/index.html)
* [imbalanced-learn.org](https://imbalanced-learn.org/stable/)

## Visualization 
* [App development - **streamlit.io**](https://streamlit.io/)
* [matplotlib.org](https://matplotlib.org/)
  * [matplotlib.org/stable/api/index](https://matplotlib.org/stable/api/index)
* [seaborn: Statistical Data Visualization - pydata.org](https://seaborn.pydata.org/)
  * [seaborn - API](https://seaborn.pydata.org/api.html)
  * [seaborn - User guide and tutorial](https://seaborn.pydata.org/tutorial.html)
* [bokeh.org](https://bokeh.org/)
  * [dask.org](https://www.dask.org/) - Scale the Python tools you love.
  * [holoviz.org](https://holoviz.org/) - High-level tools to simplify visualization in Python.
    * [colorcet](https://colorcet.holoviz.org/) - Collection of perceptually accurate colormaps.
    * [datashader](https://datashader.org/) - Accurately render even the largest data.
    * [geoviews](https://geoviews.org/) - Geographic visualizations for HoloViews.
    * [holoviews](https://holoviews.org/) - Annotate your data and let it visualize itself.
    * [hvPlot](https://hvplot.holoviz.org/) - A familiar and high-level API for data exploration and visualization.
    * [lumen](https://lumen.holoviz.org/) - Framework for visual analytics.
    * [panel](https://panel.holoviz.org) - A high-level app and dashboarding solution for Python.
    * [param](https://param.holoviz.org/) - Handle all the user-modifiable parameters, arguments, and attributes that control your code.
  * [ArviZ](https://python.arviz.org/en/0.14.0/index.html) - Package for exploratory analysis of Bayesian models in Python.
  * [Chartify](https://github.com/spotify/chartify) - Aopinionated high-level charting API.
  * [Mistic](https://github.com/MathOnco/Mistic) - Simultaneously view multiple multiplexed 2D images using pre-defined coordinates.
  * [Microscopium](https://github.com/microscopium/microscopium) - Discover new gene or drug functions by exploring large image datasets.
* [vispy.org](https://vispy.org/)
* [pygal.org](https://www.pygal.org/en/stable/)
* [folium](https://python-visualization.github.io/folium/) -  easy visualizing data that‚Äôs been manipulated in Python on an interactive leaflet map.
* [networkx.org](https://networkx.org/) - Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.
* [graphviz.org - neural-network](https://graphviz.org/Gallery/directed/neural-network.html)

## Natural Language Processing
* [spacy.io - Industrial-Strength Natural Language Processing](https://spacy.io/)
  * [spacy.io - Universe](https://spacy.io/universe)
  * [spacy.io - Models](https://spacy.io/models)
  * [spacy.io - API](https://spacy.io/api)
* [textacy: NLP, before and after spaCy](https://textacy.readthedocs.io/en/stable/)
  * [Natural Language Processing with TextaCy & SpaCy](https://jcharistech.wordpress.com/2018/11/28/natural-language-processing-with-textacy-spacy/)
* [Introduction to Natural Language Processing with Polyglot](https://jcharistech.wordpress.com/2018/12/10/introduction-to-natural-language-processing-with-polyglot/)
  * [Welcome to polyglot‚Äôs documentation!](https://polyglot.readthedocs.io/en/latest/)
* [Extractive Text Summarization Techniques With sumy](https://medium.com/@ondenyi.eric/extractive-text-summarization-techniques-with-sumy-3d3b127a0a32)
* [Natural Language Processing In Julia (Text Analysis)](https://jcharistech.wordpress.com/2018/05/01/natural-language-processing-in-julia-text-analysis/)

## Time series forecasting
* [Facebook - Prophet](https://facebook.github.io/prophet/)
  * [Facebook - Prophet: Quick start](https://facebook.github.io/prophet/docs/quick_start.html)
  * [Time Series Analysis with Facebook‚Äôs Prophet](https://jcharistech.wordpress.com/2019/07/16/time-series-analysis-with-facebooks-prophet/)

## Resources
* [tensorflow.org/resources](https://www.tensorflow.org/resources/learn-ml)
  * [tensorflow.org/resources/tools](https://www.tensorflow.org/resources/tools)
* [neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com/)
* [machinelearningmastery.com](https://machinelearningmastery.com/)
* [https://ritchieng.live/](https://ritchieng.live/)
  * [Machine Learning Resources - ritchieng.com](https://www.ritchieng.com/machine-learning-resources/)
  * [https://www.deeplearningwizard.com/](https://www.deeplearningwizard.com/)
* [madewithml.com](https://madewithml.com/)
  * [Made With ML - Github](https://github.com/GokuMohandas/Made-With-ML)
  * [Made With ML - Notebooks](https://github.com/GokuMohandas/Made-With-ML/tree/main/notebooks)
* [paperswithcode.com](https://paperswithcode.com/)
* [https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/)
* [playground.tensorflow.org - A Neural Network Playground](https://playground.tensorflow.org/)
* [https://ml-playground.com/](https://ml-playground.com/#)


## Types of ML-data
* Supervised learning.
  * **Feature vector** (Input data).
    * Qualitative - Categorical data (finite number og categories or groups).
      * Nominal Data (No inherent order).
        * One hot encoding.
      * Ordinal Data (Inherent order. E.g. ratings from 1-5).
    * Quantitative - Numerical valued data (Could be discrete or continuous).
  * **Output data** (Predictions).
    * Classification - Predict discrete classes.
      * Multiclass classification (3 classes or more)
      * Binary classification (Exacly 2 classes. E.g. Yes or No, True or False, Cat or Dog)
    * Regression - Predict continuous values
* Unsupervised learning.
* Reinforcement learning.

## Machine learning models
* Loss functions
  * L1 function
  * L2 function
    * Backpropagation (Gradient descent)
      * Learning rate
* Metrics of performance
  * Accuracy
* Models: 
  * Neural nets
    * Activation function (Without AF, this becomes a linear model)
      * Sigmoid
      * Tanh
      * RELU
* Recurrent neural networks (RNN)
  * GRU¬¥s and LSTM¬¥s
### [Youtube: Python TensorFlow for Machine Learning ‚Äì Neural Network Text Classification Tutorial](https://www.youtube.com/watch?v=VtRLrQ3Ev-U&list=PLWKjhJtqVAblQe2CCWqV4Zy3LY01Z8aF1)
‚å®Ô∏è (0:07:48) What is machine learning?
‚å®Ô∏è (0:14:00) Features (inputs)
‚å®Ô∏è (0:20:22) Outputs (predictions)
‚å®Ô∏è (0:25:05) Anatomy of a dataset
‚å®Ô∏è (0:30:22) Assessing performance
‚å®Ô∏è (0:35:01) Neural nets
‚å®Ô∏è (0:48:50) Tensorflow
...
‚å®Ô∏è (1:21:15) Recurrent neural networks

### fast.ai‚ÄîMaking neural nets uncool again
* Corporate partner program: Get help with fast.ai technologies & courses from the [partner program](https://www.fast.ai/partners.html)
* Courses: 
  * [Practical Deep Learning for Coders](https://course.fast.ai/); 
  * [Practical Data Ethics](https://ethics.fast.ai/); 
  * [Computational Linear Algebra](https://github.com/fastai/numerical-linear-algebra/blob/master/README.md)
* Software: 
  * [fastai for PyTorch](https://docs.fast.ai/); 
  * [nbdev](https://nbdev.fast.ai/)
* Book: 
  * [Practical Deep Learning for Coders with fastai and PyTorch](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527)
* In the news: 
  * [The Economist](https://www.economist.com/business/2018/10/25/new-schemes-teach-the-masses-to-build-ai); 
  * [The New York Times](https://www.nytimes.com/2018/11/18/technology/artificial-intelligence-language.html); 
  * [MIT Tech Review](https://www.technologyreview.com/s/611858/small-team-of-ai-coders-beats-googles-code/)



##### plot_decision_boundary(model, X, y) #This function was inspired by two resources:
  1. [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/neural-networks-case-study/)
  2. [404](https://github.com/madewithml/basics/blob/master/notebooks/09_Multilayer_Perceptrons/09_TF_Multilayer_Perceptrons.ipynb) 



## Linear Regression
* [Machine Learning with Python: Linear Regression](https://pieriantraining.com/linear-regression-machine-learning-python/)

## KNN - K nearest neighbors
* Wikipedia: 
  * [k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)
* SKlearn 
  * [KNN classifier package](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
  * [KNN regressor package](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)
* [KNN math notes (Cornell CS 4780, Weinberger)](http://www.cs.cornell.edu/courses/cs4780/2017sp/lectures/lecturenote02_kNN.html)

## Notes
* [chrisalbon.com/](https://chrisalbon.com/)
* [Understanding a Confusion Matrix and How to Plot It](https://www.turing.com/kb/how-to-plot-confusion-matrix)
* [Applied Machine Learning Process](https://machinelearningmastery.com/process-for-working-through-machine-learning-problems/)

## Course
* [https://www.elementsofai.dk/](https://www.elementsofai.dk/)
* [Practical Deep Learning For Coders, Part 1](https://course17.fast.ai/)
* [Cutting Edge Deep Learning For Coders, Part 2](https://course17.fast.ai/part2.html)

## Guides
* [The Ultimate Guide to Regression & Classification](https://www.superdatascience.com/blogs/the-ultimate-guide-to-regression-classification)

## Books
* [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.saxo.com/dk/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow_aurelien-geron_paperback_9781492032649#)

# Evaluation
## Machine Learning Model Evaluation
**Classification Model Evaluation Metrics/Techniques**

**Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0.

[Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.

[Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score) - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.

[F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.

[Confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) - Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagonal line).

[Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html) - Splits your dataset into multiple parts and train and tests your model on each part then evaluates performance as an average.

[Classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) - Sklearn has a built-in function called ``classification_report()`` which returns some of the main classification metrics such as precision, recall and f1-score.

[ROC Curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_score.html) - Also known as [receiver operating characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) is a plot of true positive rate versus false-positive rate.

[Area Under Curve (AUC) Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) - The area underneath the ROC curve. A perfect model achieves an AUC score of 1.0.

## Regression Model Evaluation Metrics/Techniques
[R^2 (pronounced r-squared) or the coefficient of determination](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) - Compares your model's predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1.

[Mean absolute error (MAE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.

[Mean squared error (MSE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).

**For more resources on evaluating a machine learning model, be sure to check out the following resources:**
[Scikit-Learn documentation for metrics and scoring](https://scikit-learn.org/stable/modules/model_evaluation.html) - Quantifying the quality of predictions

[Beyond Accuracy: Precision and Recall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c) - by Will Koehrsen

[Describing MSE (mean squared error) and RSME (root mean squared error)](https://stackoverflow.com/a/37861832) - Stack Overflow answer


## Reading Extension: ROC Curve + AUC
**For more information on these metrics, bookmark the following resources and refer to them when you need:**

* [ROC and AUC, Clearly Explained!](https://www.youtube.com/watch?v=4jRBRDbJemM) by StatQuest
* [ROC documentation in Scikit-Learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html) (contains code examples)
* [How the ROC curve and AUC are calculated](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) by Google's Machine Learning team

## CNN
* [CNN explainer](https://poloclub.github.io/cnn-explainer/)
* [Image Kernels](https://setosa.io/ev/image-kernels/)
* [4‚ÄîCollaborative filtering, embeddings, and more](https://course17.fast.ai/lessons/lesson4.html)
* [cs231n - Convolutional Networks/](https://cs231n.github.io/convolutional-networks/)

## Data Augmentation
* [Data Augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)

### RNN
* [How to Use the TimeseriesGenerator for Time Series Forecasting in Keras](https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/)

## Mathematics for Machine Learning
Github: [Mathematics for Machine Learning](https://github.com/dair-ai/Mathematics-for-ML.git) - A collection of resources to learn and review mathematics for machine learning.

### üìñ Books
**Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning**

* Book: [Applied Math and Machine Learning Basics](https://www.cis.upenn.edu/~jean/math-deep.pdf)
* Chapter: [Mathematics for Machine Learning](https://www.deeplearningbook.org/contents/part_basics.html)
* Book: [Probabilistic Machine Learning: An Introduction](https://mml-book.github.io)
* Book: [Mathematics for Deep Learning](https://probml.github.io/pml-book/book1.html)

* Book: [Bayes Rules!](https://www.bayesrulesbook.com/index.html)  
  * Chapter: [Bayes Rules! An Introduction to Applied Bayesian Modeling](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/index.html)

### üìÑ Papers
**The Matrix Calculus You Need For Deep Learning**

* Paper: [The Mathematics of AI](https://arxiv.org/abs/1802.01528)
* Paper: [https://arxiv.org/pdf/2203.08890.pdf](https://arxiv.org/pdf/2203.08890.pdf)

### üé• Video Lectures
**Multivariate Calculus by Imperial College London**

* Video Playlist: [Mathematics for Machine Learning - Linear Algebra](https://www.youtube.com/playlist?list=PLiiljHvN6z193BBzS0Ln8NnqQmzimTW23)
* Video Playlist: [CS229: Machine Learning](https://www.youtube.com/playlist?list=PLiiljHvN6z1_o1ztXTKWPrShrMrBLo5P3)
* Course: [https://www.youtube.com/](https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh)

### üßÆ Math Basics
**The Elements of Statistical Learning**

* Book: [https://hastie.su.domains/ElemStatLearn/](https://hastie.su.domains/ElemStatLearn/)
* Source: [Information Theory, Inference and Learning Algorithms](https://bayes.wustl.edu/etj/prob/book.pdf)
* Book: [Statistics and probability](https://www.inference.org.uk/itprnn/book.html)
* Course: [Linear Algebra Done Right](https://www.khanacademy.org/math/statistics-probability)
* Lecture and Slides: [Linear Algebra](https://linear.axler.net/LADRvideos.html)
* Course: [Calculus](https://www.khanacademy.org/math/linear-algebra)
* Course: [https://www.khanacademy.org/math/calculus-home](https://www.khanacademy.org/math/calculus-home)

## Feature Scaling
* [Feature Scaling](https://medium.com/@rahul77349/feature-scaling-why-it-is-required-8a93df1af310) - why is it required? by Rahul Saini
* [Feature Scaling with Scikit-Learn](https://benalexkeen.com/feature-scaling-with-scikit-learn/) by Ben Alex Keen
* [Feature Scaling for Machine Learning](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/) Understanding the Difference Between Normalization vs. Standardization by Aniruddha Bhandari 

## Youtube
* [(Non-technical) How Machines Learn](https://www.youtube.com/watch?v=R9OHn5ZF4Uo) - by GCP Grey
* [(Technical) Deep Learning series](https://www.youtube.com/watch?v=aircAruvnKk) - by 3Blue1Brown
* [PyTorch at Tesla](https://www.youtube.com/watch?v=oBklltKXtDE&t=173s) - Andrej Karpathy, Tesla
* [MIT 6.S191: Introduction to Deep Learning](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI)
* [youtube.com/@Deeplearningai](https://www.youtube.com/@Deeplearningai)


## Tools
* [ml-playground.com](https://ml-playground.com/#)

## Blogs
* [Transforming Model Training Workflows at Wayfair](https://www.aboutwayfair.com/careers/tech-blog/transforming-model-training-workflows-at-wayfair)

