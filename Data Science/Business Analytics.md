# Statistical terms

## What is data?

## Central tendency


## Mean
* [Arithmetic mean - Wikipedia](https://en.wikipedia.org/wiki/Arithmetic_mean) 
  * **Mean** or **Average** is the sum of a collection of numbers divided by the count of numbers in the collection
  * While the arithmetic mean is often used to report central tendencies, it is not a robust statistic: **it is greatly influenced by outliers**
  * The arithmetic mean is a data set's most commonly used and readily understood measure of central tendency. **In statistics, the term average refers to any measurement of central tendency.**

## Median
* [Median (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Median)
  * Arithmetic Median is a **positional average** and refers to the middle value in a distribution. It divides the series into two halves by first arranging the items in ascending or descending order of magnitude and then locating the middle value and is denoted by the symbol ˜X or M.
  * If the data set has an even number of observations, there is no distinct middle value and the median is usually defined to be the arithmetic mean of the two middle values: E.g. [1, 2, 3, 4, 5, 6] the median is (3+4)/2 = 3.5
  * Mainly used when skewed dataset

## Mode
* [Mode (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Mode_(statistics)) 
  * The mode is the value that appears **most frequently** in a data set. 
  * A set of data may have one mode, more than one mode, or no mode at all.
  * Like the statistical mean and median, the mode is a way of expressing, in a (usually) single number, important information about a random variable or a population. 
* For example: 
  * The mode of the sample [1, 3, 6, 6, 6, 6, 7, 7, 12, 12, 17] is 6. 
  * Given the list of data [1, 1, 2, 4, 4] its mode is not unique. A dataset, in such a case, is said to be **bimodal**, 
  * A set with more than two modes may be described as **multimodal**. 
  * [investopedia.com - Mode](https://www.investopedia.com/terms/m/mode.asp)
    * In statistics, the mode is the most commonly observed value in a set of data.
    * For the normal distribution, the mode is also the same value as the mean and median.
    * In many cases, the modal value will differ from the average value in the data.
    * Advantages:
      * The mode is easy to understand and calculate.
      * The mode is not affected by extreme values.
      * The mode is easy to identify in a data set and in a discrete frequency distribution.
      * The mode is useful for qualitative data.
      * The mode can be computed in an open-ended frequency table.
      * The mode can be located graphically.
  * Disadvantages:
      * The mode is not defined when there are no repeats in a data set.
      * The mode is not based on all values.
      * The mode is unstable when the data consist of a small number of values.
      * Sometimes the data has one mode, more than one mode, or no mode at all.

## Variance
* How much the values in your data differ from the **Mean** value
* [investopedia.com - What Is Variance in Statistics?](https://www.investopedia.com/terms/v/variance.asp)
  * The term variance refers to a **statistical measurement** of the spread between *numbers* in a data set.
  * Variance is a measurement of the spread between numbers in a data set.
  * In particular, it measures the degree of dispersion of data around the sample's mean.
  * The *square root* of the variance is the **standard deviation.**

## Standard Deviation
* [Standard deviation - Wikipedia](https://en.wikipedia.org/wiki/Standard_deviation)
  * The standard deviation is a measure of the amount of variation or dispersion of a set of values.
* [investopedia.com - Standard Deviation Formula and Uses vs. Variance](https://www.investopedia.com/terms/s/standarddeviation.asp)
    * Standard deviation measures the dispersion of a dataset relative to its mean.
    * **It is calculated as the square root of the variance.**
    * Standard deviation, in finance, is often used as a measure of a relative riskiness of an asset.
    #### *The standard deviation is graphically depicted as a bell curve's width around the mean of a data set.* **The wider the curve's width, the larger a data set's standard deviation from the mean.**
  * What Does a High Standard Deviation Mean?
    * *A large standard deviation indicates that there is a lot of variance in the observed data around the mean. This indicates that the data observed is quite spread out.* 
    * *A small or low standard deviation would indicate instead that much of the data observed is clustered tightly around the mean.*

## Normalisation or Data scaling

## Probability Theory

## Propability 
* Probability is simply how likely something is to happen. 
* Whenever we're unsure about the outcome of an event, we can talk about the probabilities of certain outcomes—how likely they are. 
* The analysis of events governed by probability is called statistics.
* [Probability - Wikipedia](https://en.wikipedia.org/wiki/Probability)
  * Probability of an event is a number that indicates how likely the event is to occur. 
  * It is expressed as a number in the range from 0 and 1. 
  * Using percentage notation, the range is from 0% to 100%. 
  * The more likely it is that the event will occur, the higher its probability. 

### Domain and Range 
* The **range** is the difference between maximum and minimum value of your data. 
* The **domain** is the values that your data can take on.


## Propability vs. Proportion
* **Proportions:** total fraction of events that happened.
* **Propability** posible outcome of an event that could happen.

## Probability mass

## Probability density
  * Probability density function
  * Comulative density function
  * Sampling variability.
    * Natural variation.
      * Often seen in biology (E.g. hight and weight) or physics (E.g. Earthquake magnitude or stars per galaxy)
    * Mesurement variation.
      * The sensors are imperfect. 
    * Complex systems.
      * Messuring some factors while ignoring others.
    * Stochasticity (Randomness).
    * SOLVING Sampling variability
      * **Taking many samples**
      * **Run statistical analysis**

## Covariance
* [Covariance - Wikipedia](https://en.wikipedia.org/wiki/Covariance)
  * In probability theory and statistics, covariance is a measure of the *joint variability* of two random variables.
* [investopedia.com - Covariance: Formula, Definition, Types, and Examples](https://www.investopedia.com/terms/c/covariance.asp)
  * Covariance is a statistical tool used to determine the relationship between the movements of two random variables.
  * When two stocks tend to move together, they are seen as having a positive covariance; when they move inversely, the covariance is negative.
  * Covariance is different from the correlation coefficient, a measure of the strength of a correlative relationship.
  * While the covariance does measure the directional relationship between two assets, it does not show the strength of the relationship between the two assets. 
    * The coefficient of correlation is a more appropriate indicator of this strength.


## Correlation
* [Correlation - Wikipedia](https://en.wikipedia.org/wiki/Correlation)
  * In statistics, **correlation** or **dependence** is any statistical relationship, whether causal or not, between two random variables or bivariate data. (**Bivariate data** is data on each of two variables, where each value of one of the variables is paired with a value of the other variable).
  * Correlations are useful because they can indicate a predictive relationship that can be exploited in practice.
    * E.g An electrical utility may produce less power on a mild day based on the correlation between electricity demand and weather.
  * in statistics it usually refers to the degree to which a pair of variables are linearly related. 
* [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)
    * **Pearson's correlation coefficient** is the covariance of the two variables divided by the product of their standard deviations. 
    * The result has always a value between −1 and 1. 
      * 1 means strong positive relationship
      * -1 means strong negative relationship
      * 0 means no relationship
  * **Correlation does NOT imply *causation***
  * #### [spurious-correlations](https://www.wnycstudios.org/podcasts/otm/articles/spurious-correlations), ref: [tylervigen.com](https://www.tylervigen.com/spurious-correlations)

# Hypothesis testing
## Dependent variable vs Independenet variable
  * DV - Dependent variables are also called **Outcome variables**
    * The variable you are trying to explain. 
  * IV - Independent variables are also called **Explanatory variables**
    * The variable you hope will explain the DV.
  * E.g. Effect on *soil moisture* (IV) on *plant growth* (DV). 

## Modelfitting 
* A **model** is an equation that explains some features of a dataset.

## Hypothesis
* Hypothesis
  * The null hypothesis.
    * In statistical analysis you test the null hypothesis.
  * Alternative hypothesis (Effect hypothesis).


## p-value
* [p-value - Wikipedia](https://en.wikipedia.org/wiki/P-value)
    * **A p-value is a statistical measurement used to validate a hypothesis against observed data.**    
    * A p-value measures the probability of obtaining the observed results, assuming that the *null hypothesis* is *true*. 
    * **The lower the p-value**, the greater the *statistical significance* of the observed difference.
    * A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis.
    * In statistics, the p-value is the probability of obtaining results at least as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct.
    * A p-value of 0.05 or lower is generally considered statistically significant.
    * P-value can serve as an alternative to—or in addition to—preselected confidence levels for hypothesis testing.
* [investopedia.com - P-Value: What It Is, How to Calculate It, and Why It Matters](https://www.investopedia.com/terms/p/p-value.asp)
* [khanacademy.org - Calculating t statistic for slope of regression line](https://www.khanacademy.org/math/ap-statistics/inference-slope-linear-regression/xfb5d8e68:test-slope-regression/v/t-statistic-slope)
* [khanacademy.org - Using a P-value to make conclusions in a test about slope](https://www.khanacademy.org/math/ap-statistics/inference-slope-linear-regression/xfb5d8e68:test-slope-regression/v/making-conclusions-for-regression-slope-hypothesis-test)


# ----- #

## Quantiles
* [Quantile - Wikipedia](https://en.wikipedia.org/wiki/Quantile)
  * In statistics and probability, quantiles are cut points dividing the range of a probability distribution into continuous intervals with *equal probabilities*, or dividing the observations in a sample in the same way.
  * **Quartiles** is when data is split into 4 equal regions

## Percentiles
* [Percentile - Wikipedia]()
  * In statistics, a **k-th percentile**, also known as **percentile score** or **centile***, is a score below which a given percentage k of scores in its frequency distribution falls (**"exclusive"** definition) or a score at or below which a given percentage falls (**"inclusive"** definition). 
  * Percentiles are expressed in the same unit of measurement as the input scores, *not in percent*; 
    * If the scores refer to human weight, the corresponding percentiles will be expressed in kilograms or pounds. 
  * It´s when data is split into 100 equal segments


## Normal Distribution
* [Normal Distribution - Wikipedia](https://en.wikipedia.org/wiki/Normal_distribution)
  * Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean.
    * The normal distribution is the proper term for a probability bell curve.
    * In a normal distribution the mean is zero and the standard deviation is 1. It has zero skew and a kurtosis of 3.
    * Normal distributions are symmetrical, but not all symmetrical distributions are normal.
    * Many naturally-occurring phenomena tend to approximate the normal distribution.
    * In finance, most pricing distributions are not, however, perfectly normal.
  * *All normal distributions can be described by just two parameters: the mean and the standard deviation.*
  * **Skewness**
    * Skewness measures the degree of symmetry of a distribution. The normal distribution is symmetric and has a skewness of zero. 
  * **Kurtosis**
    * Kurtosis measures the thickness of the tail ends of a distribution in relation to the tails of a distribution. *The normal distribution has a kurtosis equal to 3.0.*
* [investopedia.com - Normal Distribution](https://www.investopedia.com/terms/n/normaldistribution.asp)

## Shapiro–Wilk test
* [Shapiro–Wilk test - Wikipedia](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test)
  * The Shapiro–Wilk test is a test of normality.
  * The null-hypothesis of this test is that the population is normally distributed. 

## Standard error & Standard Error of the Mean
* [Standard error - Wikipedia](https://en.wikipedia.org/wiki/Standard_error)
  * The standard error (SE) of a statistic (usually an estimate of a parameter) is the standard deviation of its sampling distribution or an estimate of that standard deviation. 
  * If the statistic is the *sample mean*, it is called the **standard error of the mean (SEM).**
* [investopedia.com - Standard Error of the Mean](https://www.investopedia.com/ask/answers/042415/what-difference-between-standard-error-means-and-standard-deviation.asp)
  * *Standard deviation* **(SD)** measures the dispersion of a dataset relative to its mean.
  * SD is used frequently in statistics, and in finance is often used as a proxy for the volatility or riskiness of an investment.
  * *The standard error of the mean* **(SEM)** measures how much discrepancy is likely in a sample’s mean compared with the population mean.
  * *The SEM takes the SD and divides it by the square root of the sample size.*
  * The SEM will always be smaller than the SD.
  * *Standard error estimates the likely accuracy of a number based on the sample size.*
  * *Standard error of the mean, or SEM, indicates the size of the likely discrepancy compared to that of the larger population.*
  * *A sampling distribution is a probability distribution of a sample statistic taken from a greater population.*
  * *Researchers typically use sample data to estimate the population data, and the sampling distribution explains how the sample mean will vary from sample to sample.*
  * *The standard error of the mean is the standard deviation of the sampling distribution of the mean.*

## Z-Score
* [Standard score - Wikipedia](https://en.wikipedia.org/wiki/Standard_score)
  * Standard scores are most commonly called z-scores.
  * Other equivalent terms in use include z-values, normal scores, standardized variables and pull in high energy physics.
* [investopedia.com - How to Calculate Z-Score and Its Meaning](https://www.investopedia.com/terms/z/zscore.asp)
    * A Z-Score is a statistical measurement of a score's relationship to the mean in a group of scores.
    * A Z-score can reveal to a trader if a value is typical for a specified data set or if it is atypical.
    * In general, a Z-score of -3.0 to 3.0 suggests that a stock is trading within three standard deviations of its mean.
    * Traders have developed many methods that use z-score to identify correlations between trades, trading positions, and evaluate trading strategies.

## Confidence Intervall
* [Confidence interval - Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval)
  * In frequentist statistics, a confidence interval (CI) is a range of estimates for an unknown parameter. 
  * A confidence interval is computed at a designated confidence level; the 95% confidence level is most common, but other levels, such as 90% or 99%, are sometimes used.

* [Understanding Confidence Intervals | Easy Examples & Formulas](https://www.scribbr.com/statistics/confidence-interval/)
  * The confidence interval is the range of values that you expect your estimate to fall between a certain percentage of the time if you run your experiment again or re-sample the population in the same way.
  * The confidence level is the percentage of times you expect to reproduce an estimate between the upper and lower bounds of the confidence interval, and is set by the alpha value.
  * Confidence, in statistics, is another way to describe probability. For example, if you construct a confidence interval with a 95% confidence level, you are confident that 95 out of 100 times the estimate will fall between the upper and lower values specified by the confidence interval.
* [investopedia.com - What Is a Confidence Interval and How Do You Calculate It?](https://www.investopedia.com/terms/c/confidenceinterval.asp)
  * A confidence interval displays the probability that a parameter will fall between a pair of values around the mean.
  * Confidence intervals measure the degree of uncertainty or certainty in a sampling method.
  They are also used in hypothesis testing and regression analysis.
  * Statisticians often use p-values in conjunction with confidence intervals to gauge statistical significance.
  * They are most often constructed using confidence levels of 95% or 99%.
    ### **Confidence interval** and **confidence level** are interrelated but are not exactly the same.

## T-test
[What Is a T-Test?](https://www.investopedia.com/terms/c/confidenceinterval.asp)

* Confidence intervals are conducted using statistical methods, such as a t-test. 
* A t-test is a type of inferential statistic used to determine if there is a significant difference between the means of two groups, which may be related to certain features. 
* Calculating a t-test requires three key data values. 
  * They include the difference between the mean values from each data set (called the mean difference), 
  * the standard deviation of each group, 
  * and the number of data values of each group.

## Chi-square test
* [khanacademy.org - Chi-square statistic for hypothesis testing](https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/chi-square-statistic)
* [khanacademy.org - Chi-square goodness-of-fit example](https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/goodness-of-fit-example)
* [khanacademy.org - Introduction to the chi-square test for homogeneity](https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-tests-two-way-tables/v/chi-square-test-homogeneity)
* [Chi-square test for association (independence)](https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-tests-two-way-tables/v/chi-square-test-association-independence)



## Powerposing and p-hacking


# Online information
## Statistics
* [statology.org](https://www.statology.org/)
* [Statistics intro: Mean, median, & mode](https://www.khanacademy.org/math/cc-sixth-grade-math/cc-6th-data-statistics/mean-and-median/v/statistics-intro-mean-median-and-mode)
* [codingwithmax.com - blog](https://codingwithmax.com/blog/)
* [investopedia.com - Financial Term Dictionary](https://www.investopedia.com/financial-term-dictionary-4769738)
